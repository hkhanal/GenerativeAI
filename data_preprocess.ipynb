{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Text preprocessing\n",
        "\n",
        "* Load raw text data from the source\n",
        "* Clean raw texts\n",
        "* Crate tokens, split string into words list\n",
        "* Create token in ints (indices)\n",
        "* Create the embedding the vectors before feeding the vectors into the Networks."
      ],
      "metadata": {
        "id": "brGIxs1et1kS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FnwtxuCvRRLk"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from google.colab import drive\n",
        "drive.mount('gdrive')\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load raw text from sources"
      ],
      "metadata": {
        "id": "96ydasrovU7O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_file = \"/content/gdrive/My Drive/DagDataScienceMaterial/data_folder/TextFolder/pubmed_abs.csv\"\n",
        "df = pd.read_csv(data_file)"
      ],
      "metadata": {
        "id": "LsyrNMsYxHqf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create token, split words"
      ],
      "metadata": {
        "id": "u8_RGYcFxOOE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "texts = df[\"Abstract\"].str.cat(sep=' ').lower().split( ' ')"
      ],
      "metadata": {
        "id": "AS-aXXQi5J0Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(texts)"
      ],
      "metadata": {
        "id": "JO3E9LdzOhGg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create moel"
      ],
      "metadata": {
        "id": "7F_wY0i1SmjD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "texts[:24]"
      ],
      "metadata": {
        "id": "JAs4U0tkDAQd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Counts the words and find the unique words"
      ],
      "metadata": {
        "id": "NSyZmWcbx6Bx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "word_counts = Counter(texts)\n",
        "ll = word_counts.items()\n",
        "list(ll)[:10]"
      ],
      "metadata": {
        "id": "NU4Jkf_rSuMp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "uniq_words = sorted(word_counts, key=word_counts.get, reverse=True)"
      ],
      "metadata": {
        "id": "Qd4Bva6imj2g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "uniq_words[:10]"
      ],
      "metadata": {
        "id": "yX2tJAhIUfHt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Change words into the ints (index)"
      ],
      "metadata": {
        "id": "JPX6GKyxzKiW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "index_to_word = {index: word for index, word in enumerate(uniq_words)}\n",
        "word_to_index = {word: index for index, word in enumerate(uniq_words)}"
      ],
      "metadata": {
        "id": "WPYhtoaDUi-w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words_indexes = [word_to_index[w] for w in texts]"
      ],
      "metadata": {
        "id": "-Fj4pyU1VMHr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words_indexes[:10], texts[:10]"
      ],
      "metadata": {
        "id": "5CxG2W3IVcMl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert indices into the tensors"
      ],
      "metadata": {
        "id": "3rjB4X9p0EHT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = []\n",
        "Y = []\n",
        "sequence_length =10\n",
        "for ind in range(len(words_indexes)):\n",
        "  if len(words_indexes[ind+1:ind+sequence_length+1]) ==10:\n",
        "    X.append(torch.tensor(words_indexes[ind:ind+sequence_length]))\n",
        "    Y.append(torch.tensor(words_indexes[ind+1:ind+sequence_length+1]))\n",
        "  else:\n",
        "    pass"
      ],
      "metadata": {
        "id": "MczApmj9VjDs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torch import nn\n",
        "dataset = (X, Y)\n",
        "dataloader = DataLoader(\n",
        "        X,\n",
        "        batch_size=120\n",
        "    )"
      ],
      "metadata": {
        "id": "beMsfSBNXpFO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert data into the batches and create the numerical vectors using embedding techinques"
      ],
      "metadata": {
        "id": "b8BHOgDR0V9X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_size = len(uniq_words)\n",
        "embedding_size = 128\n",
        "n =0\n",
        "for inputs in dataloader:\n",
        "  embd = nn.Embedding(num_embeddings=input_size, embedding_dim=embedding_size)\n",
        "  xx = embd(torch.tensor(inputs))\n",
        "  print (xx.shape)\n",
        "  n +=1\n",
        "  if n >2:\n",
        "    break"
      ],
      "metadata": {
        "id": "ggMnV4gSYU0N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xx[0][0]"
      ],
      "metadata": {
        "id": "Qkcmsz5RctIh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7sEZWNOtdVps"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}